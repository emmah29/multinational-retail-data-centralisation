{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'database_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabase_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m DatabaseConnector\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_cleaning\u001b[39;00m \u001b[39mimport\u001b[39;00m DataCleaning\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtabula\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'database_utils'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from database_utils import DatabaseConnector\n",
    "from data_cleaning import DataCleaning\n",
    "import tabula\n",
    "import requests\n",
    "\n",
    "\n",
    "class DataExtractor:\n",
    "    '''\n",
    "        DataExtractor\n",
    "\n",
    "        This is a utility class.\n",
    "\n",
    "        Attributes:\n",
    "            engine\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialize an instance\n",
    "\n",
    "        Attributes\n",
    "            database_utils.DatabaseConnector: engine\n",
    "            sqlalchemy.engine.base.Connection: instance of the engine\n",
    "        '''\n",
    "        self.connector = DatabaseConnector()\n",
    "        self.connector_instance = self.connector.engine_instance\n",
    "\n",
    "    def read_rds_table(self, database_extractor, tablename):\n",
    "        '''\n",
    "        Extract the database table to a pandas DataFrame\n",
    "\n",
    "        Parameters: \n",
    "            database_extractor: sqlalchemy.engine.base.Connection: Instance of an engine to the database\n",
    "            tablename: str: Name of a table to read\n",
    "        Returns: \n",
    "            Dataframe: The data for a table\n",
    "        '''\n",
    "        # Build up the query\n",
    "        sql_query = 'SELECT * FROM ' + tablename \n",
    "        # Get the data and return it\n",
    "        return pd.read_sql_query(sql_query, database_extractor)\n",
    "\n",
    "    def retrieve_pdf_data(self, url):\n",
    "        '''\n",
    "        Extract data from a pdf to a pandas DataFrame\n",
    "\n",
    "        Parameters: \n",
    "            url: str: The url of the pdf\n",
    "        Returns: \n",
    "            Dataframe: The data within the pdf\n",
    "        '''\n",
    "        # Read the pdf into a list of DataFrames\n",
    "        dfs = tabula.read_pdf(url, pages='all')\n",
    "        # Concatenate the list into one Dataframe and return\n",
    "        return pd.concat(dfs)\n",
    "    \n",
    "    def list_number_of_stores(self, endpoint: str, header_credentials: dict):\n",
    "        '''\n",
    "        Returns the number of stores to extract\n",
    "\n",
    "        Parameters: \n",
    "            url: str: The url of the API\n",
    "            headerdictionary: str: header dictionary\n",
    "        Returns: \n",
    "            int: Number of Stores\n",
    "        '''\n",
    "        response = requests.get(endpoint, headers=header_credentials)\n",
    "        if response.status_code == 200:\n",
    "        # Access the response data as JSON\n",
    "            data = response.json()\n",
    "            number_of_stores = data['number_stores']\n",
    "            return number_of_stores\n",
    "        else:    \n",
    "            return 'API Call failed: Status Code: ' + str(response.status_code)\n",
    "\n",
    "    def retrieve_stores_data(self, endpoint: str, header_credentials: dict):\n",
    "        '''\n",
    "        Returns store data for all the stores\n",
    "\n",
    "        Parameters: \n",
    "            url: str: The url of the API\n",
    "            headerdictionary: str: header dictionary\n",
    "        Returns: \n",
    "            Object: The data within the pdf\n",
    "        '''\n",
    "        # Make multiple calls, one for each store to the API, and put the results into a Dataframe\n",
    "        # Each store has data in a dictionary. These will be concatenated into a single dictionary\n",
    "        for store_iteration in range(450):\n",
    "            # Build the endpoint\n",
    "            endpoint_with_store_number = endpoint.format(store_number=store_iteration+1)\n",
    "            # Call the API\n",
    "            response = requests.get(endpoint_with_store_number, headers=header_credentials)\n",
    "            if response.status_code == 200:\n",
    "                # Access the response data as JSON\n",
    "                if store_iteration == 0:\n",
    "                    stores_json = response.json()\n",
    "                    stores = [stores_json]\n",
    "                else:\n",
    "                    stores_json = response.json()\n",
    "                    stores.append(stores_json)\n",
    "            else:    \n",
    "                return 'API Call failed: Status Code: ' + str(response.status_code) + ' Iteration: ' + str(store_iteration+1)    \n",
    "        return pd.DataFrame(stores)\n",
    "             \n",
    "def run():\n",
    "    extractor = DataExtractor()\n",
    "    #data = extractor.read_rds_table(extractor.connector_instance, 'orders_table').set_index('index')\n",
    "    #cleansed_data = DataCleaning.clean_user_data(data)\n",
    "    #extractor.connector.upload_to_db(cleansed_data, 'dim_users')\n",
    "    #print(cleansed_data.head()) \n",
    "\n",
    "    # retrieve the pdf\n",
    "    # pdf_url = 'https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf'\n",
    "    # pdf_data = extractor.retrieve_pdf_data(pdf_url)\n",
    "    # pdf_data_cleaned = DataCleaning.clean_card_data(pdf_data)\n",
    "    # extractor.connector.upload_to_db(pdf_data_cleaned, 'dim_card_details')\n",
    "\n",
    "    header_details = {\"x-api-key\": 'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "    url_retrieve_a_store = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/{store_number}'\n",
    "    url_number_of_stores = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "    \n",
    "    number_of_stores = extractor.list_number_of_stores(url_number_of_stores, header_details)\n",
    "    print('number of stores ' + str(number_of_stores))\n",
    "    stores = extractor.retrieve_stores_data(url_retrieve_a_store, header_details)\n",
    "    print('-- and finally -- ')\n",
    "    print(stores)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Data_Extraction running main')\n",
    "    run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
